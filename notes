08/28/2023:
- Rules vs Learning
- Real Valued number equals regression
- In both classification and regression we might have two or more inputs
- having more inputs may help your solution
- having more inputs does not change whether it is classification/regression
- regression is dealing with numbers as output (continuous)
- classification is discrete
Linear Regression:
9/6/2023:
- cost functions seem like a good way to measure machine learning problems (and measuring the accuracy of the solution?)
09/13/2023:
- machine learning specialization - stanford
- kaggle has many open notebooks
- f(x) = wx + b
-      = [ w b ]| x | = dot product notation = wx + b(1)
                | 1 |
- vector notation
- Wi = Wi - alpha*( d(J)dx / d(Wi)dx )
- Theta = Theta(i) - alpha*( d(J)dx / d(Theta(i)dx )
- Useful to do the normalization of X (aka fixing size of X to make it converge)
- We are basically calculating our data points and shifting them inside of a line (maybe a parabola) 
- Calculating the cost function (from kaggle NB) = J = (1 / 2M)[(f(x)-y)^2]
- E is used as SUMMATION notation in below equations
- Wj = (1/M)E(f(Xj)-Yj)Xj
- b = (1/M)E(f(Xi)-Yi)
- theta = theta - alpha * d(J)dx / d(Theta)dx
- selecting your alpha value is very important
- expect first assignment today
- recommends doing through kaggle
- if you have a target value use regression
- categorization? 
Begin Logistic Regression:
- classification: y is either {0,1}
- positive class is the class we are trying to find? spam or not spam? spam is positive because we are trying to classify spam
- introduction of threshold
Logistic Function:
- sigmoid function
- outputs between 0 and 1 
- g(z) = 1 / (1 + e^-z) where 0 < g(x) < 1
- looking at graph on slide -> z = 0 is a good example that makes sense b/c e^-(0) = 1 / M where M = 2; final answer = 0.5
- z is really wx+b, so in reality we have e^-(wx+b)
- what type of algorithm is logistic regression? its a classification function
- 50% threshold
- decision boundary can be calculated, see example on slide
09/18/2023:
- threshold does not have to be 50% - if for tumor (for example) 20% might be a good threshold because you may want to start looking at it at a shorter threshold when it comes to health
- threshold is used to categorize the output
- is 'z' variable equal to the threshold?
- is that why the expression can change?
- z is actually desicion boundary
- Training set for cost function in logistic regression
- i = 1,...,m training examples
- cost function = error = loss function
- can we square error cost? 
- makes sense because we want to penalize error, we dont care about (+/-) values - we want absolute
- non - convex is created from squaring cost function ; non convex confuses algo bc it creates local mins
- logistic loss function
- log(1) = 0 in our case means 0 error (for CLASS 1)
- for CLASS 0, we want log(1) = 0 
- motivation of changing loss is to have a nice loss function when we do gradient descent
- using E for summation notation below
- J(W,b) = 1/M E (f(W,b) (Xi) - (Yi)) - Logistic Regression Gradient Descent (double check for correctness)
- Logistic Regression f(W, b)(X) = 1 / 1 + e^(-WX+b)
- learned linear regression (regression) and logistic regression (classification)
Overfitting in Regression
- generalization is what is important in machine learning. goal is to train your model on various inputs it has seen and give a good output for an input it has not seen
- models that are more complex than data are called 'high variance' (over fit)
- models that have more complex data than model are called 'high bias' (under fit)
- overfitting can be addressed by adding more input to model (more training examples)
- overfitting can also be addressed by selecting features to include/exclude
- too many details may end up being extra noise
- regularization is another method to address overfitting
- it reduces the size of parameters
- controls the effect of parameters
09/20/2023:
Evaluating your model (Linear Regression):
- complex model means more inputs (not necessarily good)
- train / test split - split training data into test data as well to measure error before going into production
- degree of freedom may look good for training but will ruin testing 
- report error of training model means 'test' data
- split of data should be RANDOM
- test error will have higher error than train error 
Evaluating your model (Logistic Regression):
- count number of times that the algo has misclassified
- d is the number of inputs (Model selection slide)
Train/cross validation/test split:
- J(train) pick a model d = n -> finding (W,b)
- parameters of model usually you get from gradient descent 
- J(cross validation) = min of JCV gets you d (# of inputs)
- J(test) will give you the best model
- model selection has to be done with cross validation
- data leakage
K-fold cross validation 
- K is usually 5 or 10
- this just means splitting the data into groups and taking more cross validation and try to get better error
- final validation is test data - so just one test set at the end 
Bias/Variance:
- J(train) and J(CV) data set is low and model complexity is low - just right d = 2
- J(train) and J(CV) data set is high and model complexity is low - high variance (overfit) d = 4
-  J(train) and J(CV) data set is high and model complexity is high - low variance (underfit) d = 1
How to select features?
1. Start with an empty set
2. Add the feature with the most info (correlation with output) to the feature set
3. Evaluate model performance (with cross validation)
4. Go to step 2 until model performance does not improve (much)
Example f-set = {size, #bedroom, age of house} => JCV(size) => J(test)
- building a correlation between feature and target variable (ex. price and size or price and # br, etc.)
Saturday, 09/22/2023:
Topic: Decision Tree Models
- taking derivative of J gets you the best w and b
- Cat/Dog classification problem
- purity
- cat dna and dog dna would give 100% purity
- we want to maximize purity
- we can use parameters like ear shape, face shape, whiskers
Decision 2: When do you stop splitting?
- getting everything from one node in the same class
- or at least maximize it with the # of decision depth
- if entropy is high, then impurity is high
- half and half would be the worst measure of entropy after a split 
- p0 = 1 - p1
- H(p1) = -[p1log(2)(p1) + p0log(2)(p0)] where p1 & p0 are the outcome of a decsion d1
- the best entropy basically filters out the best (at least thats how im thinking about it)
The Information Gain
- recursive algo splits the dataset and finds best information gain and checks if it has impurities, if it does, then iterate through features and see which ones give you better info gain and this algo goes until you get to maximum depth or when you have no impurities
One-hot encoding technique:
- if a categorical feature can take on k values, ...
- use binary value inside feature
Continuous Features:
- splitting on a continuous variable
- you can turn a continuous value into a decision : isWeight greater than 100? 
Regression with Decision Trees:
- continuous variable as a prediction output
- instead of entropy - we are looking at variance
09/25/2023:
- choosing a split side (that .72 is the entropy)
- entropy is taken on each set
- the resultant number on that slide is called "the information gain"
- during recursive process think bout each node as the root node
- this would fall under the supervised learning branch
- because we know we are dealing with cats and dogs (y is given)
- first decision tree was classification
- Trees are highly sensitive to the data
- People rarely use decision tress
- Tree ensembles are more practical
Sampling With Replacement
- in each training set you will have repition of the samples
- with the samples being repeated, the trees will be more focused on different subsets
- generating more training data is called 'bagging data' with replacement
- subset of training data and subset of features are both randomized
Boosted Trees: 
- adds trees sequentially by taking what the previous trees weaknesses were and adding more weight to those features on the next (current) tree
XGBoost (eXtreme Gradient Boosting):
- there are competitions
- end of material that will be on midterm 1
09/27/2023:
- hardware has improved a lot that has made the neural networks feasible 
- activation function takes all the inputs and fires the output
- layers / hidden layers
- the initial inputs are mapped to the layers and the layers are basically neurons which become 'features' basically from what i understand
- neural networks are black boxes (no visibility to the result)
- decision trees are easily followable to the result, so these would not be black boxes
- 0 - 255 range in gray scale image 
- that must be the size of a byte
- first layer, neural network is trying to learn all the different lines in the pixel
- second layer, second order details starts generating facial parts
- third layer, generates actual faces and compares to the face that was inputted
- g = 1/2M E (f(x) - y)^2 where f(x) = wx -b
- f(x) = ......................
10/02/2023:
Inference:
- Vector values
- the subscript is neuron # while the superscript is the layer #
- forward propagation is basicaly a flow of data that goes through all the layers
- the output of one layer is the input for the next
Tensorflow Implementation:
- imagine we are using temperature and duration for our inputs into our coffee roasting ml algo 
- three binary identifiers for this algo: is the duration long enough? is the temp right? does the combo of temp and duration achieve good coffee?
- combining linear models               _  _
- vector would look something like: temp|200|
                                duration|17 |
- 'Dense' constructor is from Tensorflow software
- in the slide with the code where a1 = layer1(x) - notice the layer takes an input and gives an output
- np.array be wary of matrix notation
- 'Sequential' constructor takes in your layers and creates your model as output
- numpy, pandas, soktlearn, tensorflow (tf), pytorch, XGBoost
- 'Ridge' - linear regression w/ ..
Forward Prop in numpy:
- install anymissingpackage
- colab by google shouldnt have that problem tho
- part 3 - only use gradient descent on trained dataset?
- you cant change w and b based on what you get from test data
- only the training dataset can change w and b
- once you plateau, look at the ratio to find out if you should go further or not
- if the ratio is less than the threshold, it is no longer worth it
- test data you are not trying to change anything, you are just trying to find out when to stop
10/04/2023:
- Project 1 Review:
- dot product is used to not let a feature have too much impact/influence (normalization)
- error is m x 1
- x is m x F
- for this lab f = 7 for number of features (7 inputs including the intercept)
- m = 7386 for number of data rows
10/06/2023: 
- working on one-hot encoding lab assignment
- when get product error, best thing is to print what the two matrices being multiplied look like so we can try to understand further how to solve this
- if not then we just have to trace back through the code or the data to see what the multiplying matrices or vectors should look like
- 
